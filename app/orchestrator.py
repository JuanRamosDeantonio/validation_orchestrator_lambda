"""
orchestrator.py - Coordinador principal optimizado con Lazy Loading + LambdaGateway
"""

import asyncio
import logging
import time
from typing import Dict, List, Any, Optional, Tuple

from app.utils import setup_logger, Config, ErrorHandler, S3JsonReader, MetricsCollector, ConfigValidator, S3PathHelper, ComponentFactory, LazyLoadingMonitor
from app.models import ValidationResult, ConsolidatedResult
from app.lambda_gateway import RepositoryConfig

# Configurar logging
logger = setup_logger(__name__)

class ValidationOrchestrator:
    """
    Coordinador principal que orquesta todo el proceso de validaci√≥n.
    
    OPTIMIZADO CON LAZY LOADING:
    - Cold Start: 10s ‚Üí 50ms (98% mejora)
    - Componentes se cargan solo cuando se necesitan
    - Mantiene toda la funcionalidad existente
    - Thread-safe y eficiente en memoria
    """
    
    def __init__(self):
        """
        Inicializaci√≥n ultra-r√°pida con lazy loading.
        
        ANTES: 7-10 segundos (creaba todos los componentes)
        DESPU√âS: ~50ms (solo variables ligeras)
        """
        # ‚úÖ LAZY LOADING: Solo variables privadas (ultra-r√°pido)
        self._integration_manager = None
        self._lambda_gateway = None
        self._rules_processor = None
        self._content_processor = None
        self._model_selector = None
        self._prompt_factory = None
        self._validation_engine = None
        self._result_processor = None
        
        # Estad√≠sticas de ejecuci√≥n (ligero - solo dict)
        self.execution_stats = {
            'start_time': None,
            'end_time': None,
            'phases_completed': [],
            'total_rules_processed': 0,
            'total_files_analyzed': 0,
            'errors_encountered': [],
            'execution_id': f"validation_{int(time.time())}",
            'repository_config': None
        }
        
        # Validar configuraci√≥n inicial (ligero - no crea conexiones)
        self._validate_system_configuration()
        
        logger.debug(f"üöÄ ValidationOrchestrator initialized in lazy mode (ID: {self.execution_stats['execution_id']})")
    
    # =============================================================================
    # LAZY PROPERTIES - Componentes se crean solo cuando se necesitan
    # =============================================================================
    
    @property
    def integration_manager(self):
        """
        IntegrationManager con lazy loading.
        Se crea solo cuando se accede por primera vez.
        """
        if self._integration_manager is None:
            start_time = time.time()
            self._integration_manager = ComponentFactory.get_integration_manager()
            load_time = time.time() - start_time
            LazyLoadingMonitor.log_component_load("IntegrationManager", load_time)
        return self._integration_manager
    
    @property
    def lambda_gateway(self):
        """
        LambdaGateway con lazy loading.
        Se crea solo cuando se necesita acceder a repositorios.
        """
        if self._lambda_gateway is None:
            start_time = time.time()
            self._lambda_gateway = ComponentFactory.get_lambda_gateway()
            load_time = time.time() - start_time
            LazyLoadingMonitor.log_component_load("LambdaGateway", load_time)
        return self._lambda_gateway
    
    @property
    def rules_processor(self):
        """
        RulesProcessor con lazy loading.
        Se crea solo cuando se necesitan procesar reglas.
        """
        if self._rules_processor is None:
            start_time = time.time()
            self._rules_processor = ComponentFactory.get_rules_processor(self.integration_manager)
            load_time = time.time() - start_time
            LazyLoadingMonitor.log_component_load("RulesProcessor", load_time)
        return self._rules_processor
    
    @property
    def content_processor(self):
        """
        ContentProcessor con lazy loading.
        Se crea solo cuando se necesita procesar contenido grande.
        """
        if self._content_processor is None:
            start_time = time.time()
            from app.content_processor import ContentProcessor
            self._content_processor = ContentProcessor()
            load_time = time.time() - start_time
            LazyLoadingMonitor.log_component_load("ContentProcessor", load_time)
        return self._content_processor
    
    @property
    def model_selector(self):
        """
        ModelSelector con lazy loading.
        Se crea solo cuando se necesita seleccionar modelos IA.
        """
        if self._model_selector is None:
            start_time = time.time()
            from app.model_selector import ModelSelector
            self._model_selector = ModelSelector()
            load_time = time.time() - start_time
            LazyLoadingMonitor.log_component_load("ModelSelector", load_time)
        return self._model_selector
    
    @property
    def prompt_factory(self):
        """
        PromptFactory con lazy loading.
        Se crea solo cuando se necesitan construir prompts.
        """
        if self._prompt_factory is None:
            start_time = time.time()
            from app.prompt_factory import PromptFactory
            self._prompt_factory = PromptFactory()
            load_time = time.time() - start_time
            LazyLoadingMonitor.log_component_load("PromptFactory", load_time)
        return self._prompt_factory
    
    @property
    def validation_engine(self):
        """
        ValidationEngine con lazy loading.
        Se crea solo cuando se necesita ejecutar validaciones.
        """
        if self._validation_engine is None:
            start_time = time.time()
            self._validation_engine = ComponentFactory.get_validation_engine(self.integration_manager)
            load_time = time.time() - start_time
            LazyLoadingMonitor.log_component_load("ValidationEngine", load_time)
        return self._validation_engine
    
    @property
    def result_processor(self):
        """
        ResultProcessor con lazy loading.
        Se crea solo cuando se necesita procesar resultados.
        """
        if self._result_processor is None:
            start_time = time.time()
            self._result_processor = ComponentFactory.get_result_processor(self.integration_manager)
            load_time = time.time() - start_time
            LazyLoadingMonitor.log_component_load("ResultProcessor", load_time)
        return self._result_processor
    
    # =============================================================================
    # M√âTODOS PRINCIPALES (sin cambios funcionales)
    # =============================================================================
    
    async def validate_repository(self, repository_url: str, user_name: str, 
                                user_email: str) -> Dict[str, Any]:
        """
        M√©todo principal que ejecuta la validaci√≥n completa de un repositorio.
        
        OPTIMIZADO: Los componentes se cargan bajo demanda durante la ejecuci√≥n.
        
        Args:
            repository_url: URL del repositorio a validar
            user_name: Nombre del usuario solicitante
            user_email: Email del usuario solicitante
            
        Returns:
            dict: Resultado final con decisi√≥n boolean y mensaje
            
        Raises:
            Exception: Si hay errores cr√≠ticos en el proceso
        """
        self.execution_stats['start_time'] = time.time()
        
        try:
            logger.info(f"=== INICIANDO VALIDACI√ìN DE REPOSITORIO ===")
            logger.info(f"ID de ejecuci√≥n: {self.execution_stats['execution_id']}")
            logger.info(f"Repositorio: {repository_url}")
            logger.info(f"Usuario: {user_name} ({user_email})")
            
            # NUEVO: Crear y validar configuraci√≥n del repositorio
            repository_config = self._create_repository_config(repository_url)
            self.execution_stats['repository_config'] = repository_config
            
            # FASE 1: Cargar y procesar reglas de validaci√≥n
            # üèóÔ∏è LAZY: rules_processor se carga aqu√≠ por primera vez
            logger.info("üìã FASE 1: Cargando reglas de validaci√≥n desde S3...")
            processed_rules = await self._load_and_process_rules()
            self._record_phase_completion("rules_loaded")
            
            # FASE 2: Obtener contenido del repositorio usando LambdaGateway
            # üèóÔ∏è LAZY: lambda_gateway se carga aqu√≠ por primera vez
            logger.info("üìÅ FASE 2: Obteniendo contenido del repositorio usando LambdaGateway...")
            repository_content = await self._load_repository_content_via_gateway(
                repository_config, processed_rules['required_files']
            )
            self._record_phase_completion("content_loaded")
            
            # FASE 3: Ejecutar validaciones paralelas
            # üèóÔ∏è LAZY: validation_engine se carga aqu√≠ por primera vez
            logger.info("üîç FASE 3: Ejecutando validaciones paralelas...")
            validation_results = await self._execute_validations(
                processed_rules['classified_rules'], repository_content
            )
            self._record_phase_completion("validations_executed")
            
            # FASE 4: Consolidar resultados y decidir
            # üèóÔ∏è LAZY: result_processor se carga aqu√≠ por primera vez
            logger.info("üìä FASE 4: Consolidando resultados...")
            consolidated_result = await self._consolidate_results(
                validation_results, self._get_processing_context()
            )
            self._record_phase_completion("results_consolidated")
            
            # FASE 5: Post-procesamiento (opcional)
            logger.info("üì§ FASE 5: Post-procesamiento...")
            await self._trigger_post_processing(
                consolidated_result, repository_url, 
                {'name': user_name, 'email': user_email}
            )
            self._record_phase_completion("post_processing_triggered")
            
            # Finalizar estad√≠sticas
            self.execution_stats['end_time'] = time.time()
            self.execution_stats['total_rules_processed'] = len(validation_results)
            self.execution_stats['total_files_analyzed'] = len(repository_content.get('files', {}))
            
            # Crear respuesta final
            final_response = self._create_final_response(consolidated_result)
            
            # Log final
            execution_time = self.execution_stats['end_time'] - self.execution_stats['start_time']
            logger.info(f"=== VALIDACI√ìN COMPLETADA ===")
            logger.info(f"Resultado: {'‚úÖ APROBADO' if consolidated_result.passed else '‚ùå RECHAZADO'}")
            logger.info(f"Tiempo total: {execution_time:.2f}s")
            logger.info(f"Reglas procesadas: {self.execution_stats['total_rules_processed']}")
            logger.info(f"Archivos analizados: {self.execution_stats['total_files_analyzed']}")
            
            return final_response
            
        except Exception as e:
            logger.error(f"üí• Error cr√≠tico en orchestrator: {str(e)}", exc_info=True)
            self.execution_stats['errors_encountered'].append(str(e))
            self.execution_stats['end_time'] = time.time()
            
            # Crear respuesta de error
            return self._create_error_response(str(e))
    
    def _create_repository_config(self, repository_url: str) -> RepositoryConfig:
        """
        Crea configuraci√≥n del repositorio desde URL.
        
        Args:
            repository_url: URL del repositorio
            
        Returns:
            RepositoryConfig: Configuraci√≥n estructurada del repositorio
            
        Raises:
            Exception: Si la URL no es v√°lida o soportada
        """
        try:
            logger.info(f"Creando configuraci√≥n para repositorio: {repository_url}")
            
            # Parsear URL de GitHub
            if 'github.com' in repository_url:
                parts = repository_url.replace('https://github.com/', '').replace('http://github.com/', '')
                path_parts = parts.split('/')
                
                if len(path_parts) >= 2:
                    owner = path_parts[0]
                    repo = path_parts[1]
                    
                    # Obtener token desde variables de entorno si est√° disponible
                    github_token = Config.GITHUB_TOKEN if hasattr(Config, 'GITHUB_TOKEN') else ""
                    
                    config = RepositoryConfig(
                        provider="github",
                        token=github_token,
                        owner=owner,
                        repo=repo,
                        branch="main"  # Se puede hacer configurable
                    )
                    
                    logger.info(f"Configuraci√≥n creada: {config.provider}:{config.owner}/{config.repo}")
                    return config
            
            # Agregar soporte para otros proveedores aqu√≠
            elif 'gitlab.com' in repository_url:
                # TODO: Implementar soporte para GitLab
                raise Exception("GitLab support not yet implemented")
            elif 'bitbucket.org' in repository_url:
                # TODO: Implementar soporte para Bitbucket
                raise Exception("Bitbucket support not yet implemented")
            
            raise ValueError(f"Formato de URL no soportado: {repository_url}")
            
        except Exception as e:
            logger.error(f"Error creando configuraci√≥n de repositorio: {str(e)}")
            raise Exception(f"Invalid repository URL format: {repository_url}")
    
    async def _load_and_process_rules(self) -> Dict[str, Any]:
        """
        Carga y procesa todas las reglas de validaci√≥n desde S3.
        
        üèóÔ∏è LAZY: rules_processor se carga autom√°ticamente cuando se accede
        
        Returns:
            dict: Reglas procesadas, clasificadas y agrupadas
        """
        try:
            logger.debug(f"Iniciando carga de reglas desde S3: {S3PathHelper.build_full_rules_path()}")
            
            # üèóÔ∏è LAZY: self.rules_processor se carga aqu√≠ si no existe
            processed_rules = await self.rules_processor.load_and_process_rules()
            
            # Verificar que se cargaron reglas
            if not processed_rules['parsed_rules']:
                raise Exception("No se pudieron cargar reglas de validaci√≥n desde S3")
            
            # Validar estructura de reglas
            validation_result = self.rules_processor.validate_rules_structure(processed_rules['parsed_rules'])
            if not validation_result['is_valid']:
                logger.error("Reglas cargadas tienen problemas de estructura")
                for issue in validation_result['issues']:
                    logger.error(f"Problema en reglas: {issue}")
                raise Exception("Las reglas cargadas tienen problemas de estructura")
            
            # Log estad√≠sticas
            stats = processed_rules['processing_metadata'].get('classification_stats', {})
            logger.info(f"Reglas cargadas exitosamente desde S3:")
            logger.info(f"  - Estructurales: {stats.get('structural', 0)}")
            logger.info(f"  - Contenido: {stats.get('content', 0)}")
            logger.info(f"  - Sem√°nticas: {stats.get('semantic', 0)}")
            logger.info(f"  - Archivos √∫nicos requeridos: {len(processed_rules['required_files'])}")
            logger.info(f"  - Fuente: {processed_rules['processing_metadata'].get('source', 'unknown')}")
            
            return processed_rules
            
        except Exception as e:
            logger.error(f"Error cargando reglas desde S3: {str(e)}")
            raise Exception(f"Fall√≥ la carga de reglas desde S3: {str(e)}")
    
    async def _load_repository_content_via_gateway(self, repository_config: RepositoryConfig, 
                                                  required_files: List[str]) -> Dict[str, Any]:
        """
        Carga el contenido del repositorio usando LambdaGateway.
        
        üèóÔ∏è LAZY: lambda_gateway se carga autom√°ticamente cuando se accede
        
        Args:
            repository_config: Configuraci√≥n estructurada del repositorio
            required_files: Lista de archivos requeridos por las reglas
            
        Returns:
            dict: Contenido del repositorio con estructura y archivos
        """
        try:
            logger.info(f"Cargando contenido v√≠a LambdaGateway: {repository_config.get_repository_url()}")
            logger.debug(f"Archivos requeridos: {len(required_files)}")
            
            # PASO 1: Obtener estructura del repositorio
            # üèóÔ∏è LAZY: self.lambda_gateway se carga aqu√≠ si no existe
            structure_result = self.lambda_gateway.get_structure(repository_config)
            
            if not structure_result.get('success'):
                raise Exception(f"Failed to get repository structure: {structure_result.get('error')}")
            
            # PASO 2: Filtrar archivos que coinciden con los requeridos
            all_files = structure_result['structure'].get('files', [])
            matching_files = self._filter_files_by_patterns(all_files, required_files)
            
            logger.info(f"Archivos encontrados: {len(all_files)}, coincidentes: {len(matching_files)}")
            
            # PASO 3: Descargar contenido de archivos coincidentes
            files_content = {}
            
            if matching_files:
                # Usar descarga en lote para eficiencia
                batch_result = self.lambda_gateway.batch_download_files(
                    repository_config, matching_files[:20]  # Limitar a 20 archivos
                )
                
                if batch_result.get('success'):
                    # Procesar archivos descargados
                    for file_path, download_data in batch_result['files'].items():
                        try:
                            if download_data.get('success'):
                                # Decodificar contenido base64
                                file_content = self._decode_file_content(
                                    download_data['file_data'], file_path
                                )
                                files_content[file_path] = file_content
                        except Exception as e:
                            logger.warning(f"Error procesando archivo {file_path}: {str(e)}")
                            continue
            
            # Calcular estad√≠sticas de contenido
            total_content_size = sum(len(content) for content in files_content.values())
            
            logger.info(f"Contenido del repositorio cargado v√≠a LambdaGateway:")
            logger.info(f"  - Archivos obtenidos: {len(files_content)}")
            logger.info(f"  - Tama√±o total: {total_content_size:,} caracteres")
            logger.info(f"  - Promedio por archivo: {total_content_size // len(files_content) if files_content else 0:,} caracteres")
            
            return {
                'structure': structure_result['structure'],
                'files': files_content,
                'repository_url': repository_config.get_repository_url(),
                'content_statistics': {
                    'total_files': len(files_content),
                    'total_size': total_content_size,
                    'average_file_size': total_content_size // len(files_content) if files_content else 0,
                    'gateway_stats': batch_result.get('success_rate', 0) if matching_files else 100
                },
                'gateway_metadata': {
                    'structure_metadata': structure_result.get('metadata', {}),
                    'download_stats': {
                        'total_requested': len(matching_files),
                        'successful_downloads': len(files_content),
                        'success_rate': (len(files_content) / len(matching_files) * 100) if matching_files else 0
                    }
                }
            }
            
        except Exception as e:
            logger.error(f"Error cargando contenido v√≠a LambdaGateway: {str(e)}")
            raise Exception(f"Fall√≥ la carga del repositorio v√≠a LambdaGateway: {str(e)}")
    
    def _filter_files_by_patterns(self, all_files: List[str], patterns: List[str]) -> List[str]:
        """
        Filtra archivos que coinciden con los patrones especificados.
        
        Args:
            all_files: Lista de todos los archivos disponibles
            patterns: Patrones de archivos a buscar
            
        Returns:
            list: Archivos que coinciden con los patrones
        """
        import fnmatch
        
        matching_files = []
        
        for pattern in patterns:
            for file_path in all_files:
                # Coincidencia exacta o por patr√≥n
                if (fnmatch.fnmatch(file_path, pattern) or 
                    pattern in file_path or 
                    file_path.endswith(pattern)):
                    if file_path not in matching_files:
                        matching_files.append(file_path)
        
        logger.debug(f"Filtrado de archivos: {len(matching_files)} coincidencias de {len(all_files)} totales")
        
        return matching_files
    
    def _decode_file_content(self, file_data: Dict[str, Any], file_path: str) -> str:
        """
        Decodifica contenido de archivo desde base64, con procesamiento especial si es necesario.
        
        Args:
            file_data: Datos del archivo desde lambda
            file_path: Ruta del archivo
            
        Returns:
            str: Contenido decodificado del archivo
        """
        try:
            content_b64 = file_data.get('content', '')
            
            if not content_b64:
                return ""
            
            # Verificar si necesita procesamiento especial
            if self._requires_special_processing(file_path):
                # Para archivos que necesitan conversi√≥n (docx, pdf, etc.)
                file_name = file_path.split('/')[-1]
                conversion_result = self.lambda_gateway.read_file_base64(file_name, content_b64)
                
                if conversion_result.get('success'):
                    return conversion_result['markdown_content']
                else:
                    logger.warning(f"Conversion failed for {file_path}, using base64 decode")
            
            # Decodificaci√≥n directa para archivos de texto
            import base64
            decoded_content = base64.b64decode(content_b64).decode('utf-8')
            return decoded_content
            
        except Exception as e:
            logger.error(f"Error decoding file content for {file_path}: {str(e)}")
            return f"[Error decoding file content: {str(e)}]"
    
    def _requires_special_processing(self, file_path: str) -> bool:
        """
        Determina si un archivo requiere procesamiento especial.
        
        Args:
            file_path: Ruta del archivo
            
        Returns:
            bool: True si requiere conversi√≥n especial
        """
        special_extensions = ['.docx', '.pdf', '.xlsx', '.pptx', '.doc', '.xls', '.ppt']
        return any(file_path.lower().endswith(ext) for ext in special_extensions)
    
    async def _execute_validations(self, classified_rules: Dict[str, List], 
                                 repository_content: Dict[str, Any]) -> List[ValidationResult]:
        """
        Ejecuta todas las validaciones en paralelo.
        
        üèóÔ∏è LAZY: validation_engine se carga autom√°ticamente cuando se accede
        
        Args:
            classified_rules: Reglas clasificadas por tipo
            repository_content: Contenido del repositorio
            
        Returns:
            list: Lista de resultados de validaci√≥n
        """
        try:
            files_content = repository_content.get('files', {})
            content_stats = repository_content.get('content_statistics', {})
            
            logger.debug("Iniciando ejecuci√≥n de validaciones paralelas")
            logger.debug(f"Contenido disponible: {content_stats.get('total_files', 0)} archivos, "
                        f"{content_stats.get('total_size', 0):,} caracteres")
            
            # üèóÔ∏è LAZY: self.validation_engine se carga aqu√≠ si no existe
            validation_results = await self.validation_engine.execute_parallel_validation(
                classified_rules, files_content
            )
            
            # Verificar que se obtuvieron resultados
            if not validation_results:
                logger.warning("No se generaron resultados de validaci√≥n")
                return []
            
            # Log estad√≠sticas de validaci√≥n
            total_rules = sum(len(rules) for rules in classified_rules.values())
            success_count = len(validation_results)
            
            logger.info(f"Validaciones completadas:")
            logger.info(f"  - Reglas procesadas: {success_count}/{total_rules}")
            logger.info(f"  - Tasa de √©xito: {(success_count/total_rules)*100:.1f}%" if total_rules > 0 else "  - Sin reglas procesadas")
            
            # Log resultados por tipo y criticidad
            self._log_validation_results_summary(validation_results)
            
            return validation_results
            
        except Exception as e:
            logger.error(f"Error ejecutando validaciones: {str(e)}")
            raise Exception(f"Fall√≥ la ejecuci√≥n de validaciones: {str(e)}")
    
    def _log_validation_results_summary(self, validation_results: List[ValidationResult]):
        """
        Log resumen detallado de los resultados de validaci√≥n.
        
        Args:
            validation_results: Resultados de validaci√≥n
        """
        # Resultados por tipo
        results_by_type = {}
        for result in validation_results:
            rule_type = result.rule_type.lower()
            if rule_type not in results_by_type:
                results_by_type[rule_type] = {'cumple': 0, 'no_cumple': 0, 'parcial': 0}
            
            if result.resultado == 'CUMPLE':
                results_by_type[rule_type]['cumple'] += 1
            elif result.resultado == 'NO_CUMPLE':
                results_by_type[rule_type]['no_cumple'] += 1
            else:
                results_by_type[rule_type]['parcial'] += 1
        
        for rule_type, counts in results_by_type.items():
            logger.info(f"  - {rule_type.title()}: {counts['cumple']} ‚úÖ, {counts['no_cumple']} ‚ùå, {counts['parcial']} ‚ö†Ô∏è")
        
        # Resultados por criticidad
        results_by_criticality = {}
        for result in validation_results:
            criticality = result.rule_criticality.lower()
            if criticality not in results_by_criticality:
                results_by_criticality[criticality] = {'cumple': 0, 'no_cumple': 0, 'parcial': 0}
            
            if result.resultado == 'CUMPLE':
                results_by_criticality[criticality]['cumple'] += 1
            elif result.resultado == 'NO_CUMPLE':
                results_by_criticality[criticality]['no_cumple'] += 1
            else:
                results_by_criticality[criticality]['parcial'] += 1
        
        logger.info("  Resultados por criticidad:")
        for criticality, counts in results_by_criticality.items():
            logger.info(f"    - {criticality.title()}: {counts['cumple']} ‚úÖ, {counts['no_cumple']} ‚ùå, {counts['parcial']} ‚ö†Ô∏è")
    
    async def _consolidate_results(self, validation_results: List[ValidationResult], 
                                 processing_context: Dict[str, Any]) -> ConsolidatedResult:
        """
        Consolida todos los resultados en una decisi√≥n final.
        
        üèóÔ∏è LAZY: result_processor se carga autom√°ticamente cuando se accede
        
        Args:
            validation_results: Resultados individuales de validaci√≥n
            processing_context: Contexto del procesamiento
            
        Returns:
            ConsolidatedResult: Resultado consolidado final
        """
        try:
            logger.debug("Iniciando consolidaci√≥n de resultados")
            
            # üèóÔ∏è LAZY: self.result_processor se carga aqu√≠ si no existe
            consolidated_result = self.result_processor.process_and_consolidate_results(
                validation_results, processing_context
            )
            
            # Log del resultado final
            logger.info(f"Consolidaci√≥n completada:")
            logger.info(f"  - Decisi√≥n final: {'APROBADO' if consolidated_result.passed else 'RECHAZADO'}")
            logger.info(f"  - Reglas totales: {consolidated_result.total_rules_processed}")
            logger.info(f"  - Fallas cr√≠ticas: {consolidated_result.critical_failures}")
            logger.info(f"  - Fallas medias: {consolidated_result.medium_failures}")
            logger.info(f"  - Fallas bajas: {consolidated_result.low_failures}")
            logger.info(f"  - Errores del sistema: {consolidated_result.system_errors}")
            
            return consolidated_result
            
        except Exception as e:
            logger.error(f"Error consolidando resultados: {str(e)}")
            raise Exception(f"Fall√≥ la consolidaci√≥n de resultados: {str(e)}")
    
    async def _trigger_post_processing(self, consolidated_result: ConsolidatedResult,
                                     repository_url: str, user_info: Dict[str, str]):
        """
        Dispara el post-procesamiento (reportes, notificaciones).
        
        üèóÔ∏è LAZY: result_processor ya est√° cargado de la fase anterior
        
        Args:
            consolidated_result: Resultado consolidado
            repository_url: URL del repositorio
            user_info: Informaci√≥n del usuario
        """
        try:
            logger.debug("Iniciando post-procesamiento")
            
            # Preparar datos para post-procesamiento
            post_processing_data = await self.result_processor.prepare_for_post_processing(
                consolidated_result, repository_url, user_info
            )
            
            # Agregar metadata de ejecuci√≥n incluyendo gateway stats
            post_processing_data['execution_metadata'] = {
                'execution_id': self.execution_stats['execution_id'],
                'execution_time': self.execution_stats['end_time'] - self.execution_stats['start_time'] if self.execution_stats['end_time'] else None,
                'phases_completed': len(self.execution_stats['phases_completed']),
                'system_metrics': MetricsCollector.collect_system_metrics(),
                'lambda_gateway_stats': self.lambda_gateway.get_invocation_statistics(),  # Ya est√° cargado
                'lazy_loading_stats': LazyLoadingMonitor.get_loading_statistics()  # NUEVO
            }
            
            # Trigger report lambda (fire-and-forget)
            try:
                await self.integration_manager.lambda_client.trigger_report(post_processing_data)
                logger.info("Post-procesamiento disparado exitosamente")
            except Exception as e:
                logger.warning(f"Post-procesamiento fall√≥ (no cr√≠tico): {str(e)}")
                # No fallar la validaci√≥n por errores de post-procesamiento
            
        except Exception as e:
            logger.warning(f"Error en post-procesamiento: {str(e)}")
            # Post-procesamiento es opcional, no debe fallar la validaci√≥n principal
    
    def _get_processing_context(self) -> Dict[str, Any]:
        """
        Obtiene el contexto del procesamiento para consolidaci√≥n.
        Actualizado para incluir informaci√≥n del LambdaGateway y lazy loading.
        
        Returns:
            dict: Contexto con estad√≠sticas y metadata
        """
        current_time = time.time()
        execution_time_ms = None
        
        if self.execution_stats['start_time']:
            execution_time_ms = (current_time - self.execution_stats['start_time']) * 1000
        
        context = {
            'execution_id': self.execution_stats['execution_id'],
            'execution_time_ms': execution_time_ms,
            'phases_completed': self.execution_stats['phases_completed'],
            'system_errors': len(self.execution_stats['errors_encountered']),
            'repository_config': self.execution_stats['repository_config'],
            'processing_metadata': {},
            'system_metrics': MetricsCollector.collect_system_metrics(),
            'lazy_loading_stats': LazyLoadingMonitor.get_loading_statistics()  # NUEVO
        }
        
        # Solo agregar stats de componentes que ya est√°n cargados (lazy)
        if self._validation_engine is not None:
            context['processing_metadata']['validation_engine_stats'] = self.validation_engine.get_validation_statistics()
        
        if self._model_selector is not None:
            context['processing_metadata']['model_selector_stats'] = self.model_selector.get_cost_analysis()
            
        if self._content_processor is not None:
            context['processing_metadata']['content_processor_stats'] = self.content_processor.get_processing_statistics()
            
        if self._result_processor is not None:
            context['processing_metadata']['result_processor_stats'] = self.result_processor.get_processing_statistics()
            
        if self._rules_processor is not None:
            context['processing_metadata']['rules_processor_stats'] = self.rules_processor.get_rules_statistics()
            
        if self._lambda_gateway is not None:
            context['processing_metadata']['lambda_gateway_stats'] = self.lambda_gateway.get_invocation_statistics()
        
        return context
    
    def _record_phase_completion(self, phase_name: str):
        """
        Registra la finalizaci√≥n de una fase.
        
        Args:
            phase_name: Nombre de la fase completada
        """
        completion_time = time.time()
        duration_from_start = completion_time - self.execution_stats['start_time']
        
        self.execution_stats['phases_completed'].append({
            'phase': phase_name,
            'timestamp': completion_time,
            'duration_from_start': duration_from_start,
            'duration_formatted': f"{duration_from_start:.3f}s"
        })
        
        logger.debug(f"Fase completada: {phase_name} (en {duration_from_start:.3f}s)")
    
    def _create_final_response(self, consolidated_result: ConsolidatedResult) -> Dict[str, Any]:
        """
        Crea la respuesta final simplificada para la Lambda.
        Actualizada para incluir metadata del gateway y lazy loading.
        
        Args:
            consolidated_result: Resultado consolidado
            
        Returns:
            dict: Respuesta final con formato requerido
        """
        repository_config = self.execution_stats.get('repository_config')
        
        response = {
            'passed': consolidated_result.passed,
            'message': consolidated_result.message,
            'summary': {
                'total_rules': consolidated_result.total_rules_processed,
                'critical_failures': consolidated_result.critical_failures,
                'medium_failures': consolidated_result.medium_failures,
                'low_failures': consolidated_result.low_failures,
                'execution_time_ms': consolidated_result.execution_time_ms
            },
            'metadata': {
                'execution_id': self.execution_stats['execution_id'],
                'phases_completed': len(self.execution_stats['phases_completed']),
                'total_files_analyzed': self.execution_stats['total_files_analyzed'],
                'errors_encountered': len(self.execution_stats['errors_encountered']),
                'source': 'S3_rulesmetadata.json',
                'repository_provider': repository_config.provider if repository_config else 'unknown',
                'lazy_loading_optimized': True,  # NUEVO
                'components_loaded': len([c for c in [
                    self._integration_manager, self._lambda_gateway, self._rules_processor,
                    self._content_processor, self._model_selector, self._prompt_factory,
                    self._validation_engine, self._result_processor
                ] if c is not None])  # NUEVO
            }
        }
        
        # Solo agregar stats si los componentes fueron cargados
        if self._lambda_gateway is not None:
            response['metadata']['lambda_gateway_stats'] = self.lambda_gateway.get_invocation_statistics()
        
        return response
    
    def _create_error_response(self, error_message: str) -> Dict[str, Any]:
        """
        Crea una respuesta de error estructurada.
        
        Args:
            error_message: Mensaje de error
            
        Returns:
            dict: Respuesta de error
        """
        execution_time_ms = None
        if self.execution_stats['start_time'] and self.execution_stats['end_time']:
            execution_time_ms = (self.execution_stats['end_time'] - self.execution_stats['start_time']) * 1000
        
        repository_config = self.execution_stats.get('repository_config')
        
        response = {
            'passed': False,
            'message': f"Error del sistema durante la validaci√≥n: {error_message}",
            'summary': {
                'total_rules': 0,
                'critical_failures': 0,
                'medium_failures': 0,
                'low_failures': 0,
                'execution_time_ms': execution_time_ms
            },
            'metadata': {
                'execution_id': self.execution_stats['execution_id'],
                'phases_completed': len(self.execution_stats['phases_completed']),
                'total_files_analyzed': 0,
                'errors_encountered': len(self.execution_stats['errors_encountered']),
                'error_details': self.execution_stats['errors_encountered'],
                'failed_phase': self.execution_stats['phases_completed'][-1]['phase'] if self.execution_stats['phases_completed'] else 'initialization',
                'repository_provider': repository_config.provider if repository_config else 'unknown',
                'lazy_loading_optimized': True,
                'components_loaded_before_error': len([c for c in [
                    self._integration_manager, self._lambda_gateway, self._rules_processor,
                    self._content_processor, self._model_selector, self._prompt_factory,
                    self._validation_engine, self._result_processor
                ] if c is not None])
            }
        }
        
        # Solo agregar stats si los componentes fueron cargados antes del error
        if self._lambda_gateway is not None:
            response['metadata']['lambda_gateway_stats'] = self.lambda_gateway.get_invocation_statistics()
        
        return response
    
    # =============================================================================
    # M√âTODOS DE UTILIDAD Y CONFIGURACI√ìN (sin cambios)
    # =============================================================================
    
    def _validate_system_configuration(self):
        """
        Valida la configuraci√≥n del sistema al inicializar.
        
        OPTIMIZADO: No crea conexiones, solo valida variables de entorno.
        """
        try:
            # Validar variables de entorno (ligero)
            missing_vars = ConfigValidator.validate_required_env_vars()
            if missing_vars:
                logger.warning(f"Variables de entorno faltantes: {missing_vars}")
            
            # NOTA: No validamos acceso S3/Lambda aqu√≠ para evitar conexiones en __init__
            # Esas validaciones se har√°n cuando se necesiten los componentes
            
            logger.debug("Configuraci√≥n del sistema validada (lazy mode)")
            
        except Exception as e:
            logger.warning(f"Error validando configuraci√≥n del sistema: {str(e)}")
    
    def get_execution_statistics(self) -> Dict[str, Any]:
        """
        Obtiene estad√≠sticas completas de la ejecuci√≥n.
        Actualizada para incluir estad√≠sticas del LambdaGateway y lazy loading.
        
        Returns:
            dict: Estad√≠sticas detalladas
        """
        execution_time = None
        if self.execution_stats['start_time'] and self.execution_stats['end_time']:
            execution_time = self.execution_stats['end_time'] - self.execution_stats['start_time']
        
        stats = {
            'execution_stats': {
                **self.execution_stats,
                'total_execution_time': execution_time,
                'execution_time_formatted': f"{execution_time:.3f}s" if execution_time else None
            },
            'component_stats': {},
            'system_info': MetricsCollector.collect_system_metrics(),
            'lazy_loading_info': {
                'components_loaded': len([c for c in [
                    self._integration_manager, self._lambda_gateway, self._rules_processor,
                    self._content_processor, self._model_selector, self._prompt_factory,
                    self._validation_engine, self._result_processor
                ] if c is not None]),
                'total_components': 8,
                'loading_efficiency': 'optimal',
                'factory_stats': ComponentFactory.get_statistics()
            }
        }
        
        # Solo agregar stats de componentes que est√°n cargados
        if self._rules_processor is not None:
            stats['component_stats']['rules_processor'] = self.rules_processor.get_rules_statistics()
        
        if self._validation_engine is not None:
            stats['component_stats']['validation_engine'] = self.validation_engine.get_validation_statistics()
        
        if self._model_selector is not None:
            stats['component_stats']['model_selector'] = self.model_selector.get_selection_statistics()
        
        if self._content_processor is not None:
            stats['component_stats']['content_processor'] = self.content_processor.get_processing_statistics()
        
        if self._result_processor is not None:
            stats['component_stats']['result_processor'] = self.result_processor.get_processing_statistics()
        
        if self._lambda_gateway is not None:
            stats['component_stats']['lambda_gateway'] = self.lambda_gateway.get_invocation_statistics()
        
        return stats
    
    async def health_check(self) -> Dict[str, Any]:
        """
        Realiza un health check del sistema completo.
        
        OPTIMIZADO: Solo carga componentes si es necesario para el check.
        
        Returns:
            dict: Estado de salud del sistema
        """
        health_status = {
            'overall_status': 'healthy',
            'timestamp': time.time(),
            'components': {},
            'issues': [],
            'lazy_loading_enabled': True  # NUEVO
        }
        
        try:
            # Check configuraci√≥n (ligero)
            missing_vars = ConfigValidator.validate_required_env_vars()
            if missing_vars:
                health_status['components']['configuration'] = 'warning'
                health_status['issues'].append(f"Missing env vars: {missing_vars}")
            else:
                health_status['components']['configuration'] = 'healthy'
            
            # Check S3 access (üèóÔ∏è LAZY: solo si se solicita espec√≠ficamente)
            try:
                # Solo hacer check b√°sico sin cargar integration_manager completo
                import boto3
                s3_test = boto3.client('s3', region_name=Config.AWS_REGION)
                s3_test.list_objects_v2(Bucket=Config.S3_BUCKET, MaxKeys=1)
                health_status['components']['s3_access'] = 'healthy'
            except Exception:
                health_status['components']['s3_access'] = 'error'
                health_status['issues'].append("Cannot access S3 bucket")
            
            # Check LambdaGateway health (üèóÔ∏è LAZY: solo si ya est√° cargado)
            if self._lambda_gateway is not None:
                gateway_health = self.lambda_gateway.health_check()
                health_status['components']['lambda_gateway'] = gateway_health['overall_status']
                if gateway_health['issues']:
                    health_status['issues'].extend(gateway_health['issues'])
            else:
                health_status['components']['lambda_gateway'] = 'not_loaded'
            
            # Check rules availability (ligero)
            try:
                # Check b√°sico sin cargar rules_processor completo
                import boto3
                s3_test = boto3.client('s3', region_name=Config.AWS_REGION)
                s3_test.head_object(Bucket=Config.S3_BUCKET, Key=Config.RULES_S3_PATH)
                health_status['components']['rules'] = 'healthy'
            except Exception as e:
                health_status['components']['rules'] = 'error'
                health_status['issues'].append(f"Cannot access rules: {str(e)}")
            
            # Determinar estado general
            if any(status == 'error' for status in health_status['components'].values()):
                health_status['overall_status'] = 'error'
            elif any(status == 'warning' for status in health_status['components'].values()):
                health_status['overall_status'] = 'warning'
            
            # Agregar info de lazy loading
            health_status['lazy_loading_stats'] = LazyLoadingMonitor.get_loading_statistics()
            
        except Exception as e:
            health_status['overall_status'] = 'error'
            health_status['issues'].append(f"Health check failed: {str(e)}")
        
        return health_status