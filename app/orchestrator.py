"""
orchestrator.py - Coordinador principal LIMPIO (REFACTORIZADO)
MEJORAS: State Pattern para fases de validaci√≥n
- validate_repository: 15+ ‚Üí 4 complejidad ciclom√°tica
- Cada fase es una clase independiente con responsabilidad √∫nica
- Mejor manejo de errores y contexto
"""

import asyncio
import logging
import time
from typing import Dict, List, Any, Optional, Tuple
from abc import ABC, abstractmethod

# IMPORTS LIMPIOS - Sin referencias a mocks
from shared import (
    setup_logger, Config, ErrorHandler, S3JsonReader, MetricsCollector, 
    ConfigValidator, S3PathHelper, ComponentFactory, LazyLoadingMonitor,
    ValidationResult, ConsolidatedResult, RepositoryConfig
)

# Configurar logging
logger = setup_logger(__name__)

# =============================================================================
# STATE PATTERN PARA FASES DE VALIDACI√ìN - Complejidad reducida 15+ ‚Üí 4
# =============================================================================

class ValidationPhase(ABC):
    """Base class para fases de validaci√≥n usando State pattern."""
    
    def __init__(self, orchestrator):
        self.orchestrator = orchestrator
    
    @abstractmethod
    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Ejecuta la fase espec√≠fica y retorna contexto actualizado."""
        pass
    
    @abstractmethod
    def get_phase_name(self) -> str:
        """Retorna nombre de la fase para logging y error handling."""
        pass
    
    def log_phase_start(self):
        """Log estandarizado de inicio de fase."""
        logger.info(f"üìã FASE {self.get_phase_name().upper()}: Iniciando...")
    
    def log_phase_completion(self, context: Dict[str, Any]):
        """Log estandarizado de finalizaci√≥n de fase."""
        logger.info(f"‚úÖ FASE {self.get_phase_name().upper()}: Completada exitosamente")
        self.orchestrator._record_phase_completion(self.get_phase_name())


class RulesLoadingPhase(ValidationPhase):
    """Fase 1: Carga y procesamiento de reglas desde S3."""
    
    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        self.log_phase_start()
        
        # üèóÔ∏è LAZY: rules_manager se carga aqu√≠ por primera vez
        processed_rules = await self.orchestrator._load_and_process_rules()
        
        context['processed_rules'] = processed_rules
        self.log_phase_completion(context)
        
        return context
    
    def get_phase_name(self) -> str:
        return "rules_loading"


class ContentLoadingPhase(ValidationPhase):
    """Fase 2: Obtenci√≥n de contenido del repositorio."""
    
    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        self.log_phase_start()
        
        # üèóÔ∏è LAZY: repository_access_manager se carga aqu√≠ por primera vez
        repository_content = await self.orchestrator._load_repository_content_via_real_services(
            context['repository_config'], 
            context['processed_rules']['required_files']
        )
        
        context['repository_content'] = repository_content
        self.log_phase_completion(context)
        
        return context
    
    def get_phase_name(self) -> str:
        return "content_loading"


class ValidationExecutionPhase(ValidationPhase):
    """Fase 3: Ejecuci√≥n de validaciones paralelas."""
    
    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        self.log_phase_start()
        
        # üèóÔ∏è LAZY: validation_engine se carga aqu√≠ por primera vez
        validation_results = await self.orchestrator._execute_validations(
            context['processed_rules']['classified_rules'],
            context['repository_content']
        )
        
        context['validation_results'] = validation_results
        self.log_phase_completion(context)
        
        return context
    
    def get_phase_name(self) -> str:
        return "validation_execution"


class ResultsConsolidationPhase(ValidationPhase):
    """Fase 4: Consolidaci√≥n de resultados."""
    
    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        self.log_phase_start()
        
        consolidated_result = await self.orchestrator._consolidate_results(
            context['validation_results'], 
            self.orchestrator._get_processing_context()
        )
        
        context['consolidated_result'] = consolidated_result
        self.log_phase_completion(context)
        
        return context
    
    def get_phase_name(self) -> str:
        return "results_consolidation"


class PostProcessingPhase(ValidationPhase):
    """Fase 5: Post-procesamiento con servicios AWS."""
    
    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        self.log_phase_start()
        
        await self.orchestrator._trigger_post_processing(
            context['consolidated_result'], 
            context['repository_url'], 
            {'name': context['user_name'], 'email': context['user_email']}
        )
        
        self.log_phase_completion(context)
        
        return context
    
    def get_phase_name(self) -> str:
        return "post_processing"


# =============================================================================
# VALIDATION ORCHESTRATOR REFACTORIZADO
# =============================================================================

class ValidationOrchestrator:
    """
    Coordinador principal que orquesta todo el proceso de validaci√≥n.
    
    REFACTORIZADO CON STATE PATTERN:
    - validate_repository: 15+ ‚Üí 4 complejidad ciclom√°tica
    - Cada fase es independiente y testeable
    - Mejor error handling y recovery
    - Contexto centralizado para todas las fases
    """
    
    def __init__(self):
        """
        Inicializaci√≥n ultra-r√°pida con lazy loading.
        MANTIENE: ~50ms de inicializaci√≥n con lazy loading
        NUEVO: State pattern para fases de validaci√≥n
        """
        # ‚úÖ LAZY LOADING: Solo variables privadas (ultra-r√°pido)
        self._repository_access_manager = None
        self._rules_manager = None
        self._validation_engine = None
        
        # State pattern: Lista de fases de validaci√≥n (NUEVO)
        self._phases = [
            RulesLoadingPhase(self),
            ContentLoadingPhase(self),
            ValidationExecutionPhase(self),
            ResultsConsolidationPhase(self),
            PostProcessingPhase(self)
        ]
        
        # Estad√≠sticas de ejecuci√≥n (ligero - solo dict)
        self.execution_stats = {
            'start_time': None,
            'end_time': None,
            'phases_completed': [],
            'total_rules_processed': 0,
            'total_files_analyzed': 0,
            'errors_encountered': [],
            'execution_id': f"validation_{int(time.time())}",
            'repository_config': None,
            'uses_real_services': True,
            'state_pattern_applied': True  # NUEVO: Indicador de refactoring
        }
        
        # Validar configuraci√≥n inicial (ligero - no crea conexiones)
        self._validate_system_configuration()
        
        logger.debug(f"üöÄ ValidationOrchestrator initialized with State Pattern (ID: {self.execution_stats['execution_id']}) - REAL SERVICES")
    
    # =============================================================================
    # LAZY PROPERTIES - Componentes REALES se crean solo cuando se necesitan
    # =============================================================================
    
    @property
    def repository_access_manager(self):
        """RepositoryAccessManager REAL con lazy loading."""
        if self._repository_access_manager is None:
            start_time = time.time()
            self._repository_access_manager = ComponentFactory.get_repository_access_manager()
            load_time = time.time() - start_time
            LazyLoadingMonitor.log_component_load("RepositoryAccessManager", load_time)
        return self._repository_access_manager
    
    @property
    def rules_manager(self):
        """RulesManager REAL con lazy loading."""
        if self._rules_manager is None:
            start_time = time.time()
            self._rules_manager = ComponentFactory.get_rules_manager(self.repository_access_manager)
            load_time = time.time() - start_time
            LazyLoadingMonitor.log_component_load("RulesManager", load_time)
        return self._rules_manager
    
    @property
    def validation_engine(self):
        """ValidationEngine REAL con lazy loading."""
        if self._validation_engine is None:
            start_time = time.time()
            self._validation_engine = ComponentFactory.get_validation_engine(self.repository_access_manager)
            load_time = time.time() - start_time
            LazyLoadingMonitor.log_component_load("ValidationEngine", load_time)
        return self._validation_engine
    
    # =============================================================================
    # M√âTODO PRINCIPAL REFACTORIZADO CON STATE PATTERN
    # =============================================================================
    
    async def validate_repository(self, repository_url: str, user_name: str, 
                                user_email: str) -> Dict[str, Any]:
        """
        M√©todo principal que ejecuta la validaci√≥n completa usando State Pattern.
        
        COMPLEJIDAD REDUCIDA: 15+ ‚Üí 4 decision paths
        - Inicializaci√≥n (1)
        - Ejecuci√≥n de fases (1) 
        - Finalizaci√≥n (1)
        - Error handling (1)
        
        Args:
            repository_url: URL del repositorio a validar
            user_name: Nombre del usuario solicitante
            user_email: Email del usuario solicitante
            
        Returns:
            dict: Resultado final con decisi√≥n boolean y mensaje
        """
        self.execution_stats['start_time'] = time.time()
        
        try:
            logger.info(f"=== INICIANDO VALIDACI√ìN DE REPOSITORIO (STATE PATTERN + SERVICIOS REALES) ===")
            logger.info(f"ID de ejecuci√≥n: {self.execution_stats['execution_id']}")
            logger.info(f"Repositorio: {repository_url}")
            logger.info(f"Usuario: {user_name} ({user_email})")
            
            # INICIALIZACI√ìN: Crear contexto inicial (decision path 1)
            context = self._initialize_context(repository_url, user_name, user_email)
            
            # EJECUCI√ìN: Ejecutar fases secuencialmente usando State Pattern (decision path 2)
            for phase in self._phases:
                try:
                    context = await phase.execute(context)
                except Exception as e:
                    return self._handle_phase_error(e, phase.get_phase_name())
            
            # FINALIZACI√ìN: Crear respuesta final (decision path 3)
            final_response = self._finalize_validation(context)
            
            # Log final
            execution_time = self.execution_stats['end_time'] - self.execution_stats['start_time']
            logger.info(f"=== VALIDACI√ìN COMPLETADA CON STATE PATTERN ===")
            logger.info(f"Resultado: {'‚úÖ APROBADO' if context['consolidated_result'].passed else '‚ùå RECHAZADO'}")
            logger.info(f"Tiempo total: {execution_time:.2f}s")
            logger.info(f"Fases completadas: {len(self.execution_stats['phases_completed'])}")
            
            return final_response
            
        except Exception as e:  # decision path 4
            logger.error(f"üí• Error cr√≠tico en orchestrator: {str(e)}", exc_info=True)
            self.execution_stats['errors_encountered'].append(str(e))
            self.execution_stats['end_time'] = time.time()
            
            return self._create_error_response(str(e))
    
    def _initialize_context(self, repository_url: str, user_name: str, user_email: str) -> Dict[str, Any]:
        """
        Inicializa contexto de validaci√≥n centralizado.
        NUEVO: Contexto compartido entre todas las fases
        """
        # Crear y validar configuraci√≥n del repositorio
        repository_config = self._create_repository_config(repository_url)
        self.execution_stats['repository_config'] = repository_config
        
        return {
            'repository_url': repository_url,
            'user_name': user_name,
            'user_email': user_email,
            'repository_config': repository_config,
            'start_time': self.execution_stats['start_time']
        }
    
    def _finalize_validation(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Finaliza validaci√≥n y crea respuesta final.
        NUEVO: Centralizaci√≥n de finalizaci√≥n
        """
        # Actualizar estad√≠sticas finales
        self.execution_stats['end_time'] = time.time()
        self.execution_stats['total_rules_processed'] = context['consolidated_result'].total_rules_processed
        self.execution_stats['total_files_analyzed'] = len(context['repository_content'].get('files', {}))
        
        # Crear respuesta final
        return self._create_final_response(context['consolidated_result'])
    
    def _handle_phase_error(self, error: Exception, phase_name: str) -> Dict[str, Any]:
        """
        Maneja errores espec√≠ficos de fases con contexto.
        NUEVO: Error handling granular por fase
        """
        logger.error(f"üí• Error en fase '{phase_name}': {str(error)}", exc_info=True)
        
        self.execution_stats['errors_encountered'].append(f"Phase {phase_name}: {str(error)}")
        self.execution_stats['end_time'] = time.time()
        
        # Crear respuesta de error con informaci√≥n de fase
        error_response = self._create_error_response(str(error))
        error_response['metadata']['failed_phase'] = phase_name
        error_response['metadata']['phases_completed_before_error'] = len(self.execution_stats['phases_completed'])
        
        return error_response
    
    # =============================================================================
    # M√âTODOS DE FASE DELEGADOS (mantiene funcionalidad original)
    # =============================================================================
    
    def _create_repository_config(self, repository_url: str) -> RepositoryConfig:
        """Crea configuraci√≥n del repositorio desde URL."""
        try:
            logger.info(f"Creando configuraci√≥n para repositorio: {repository_url}")
            
            # Parsear URL de GitHub
            if 'github.com' in repository_url:
                parts = repository_url.replace('https://github.com/', '').replace('http://github.com/', '')
                path_parts = parts.split('/')
                
                if len(path_parts) >= 2:
                    owner = path_parts[0]
                    repo = path_parts[1]
                    
                    # Obtener token desde variables de entorno si est√° disponible
                    github_token = Config.GITHUB_TOKEN if hasattr(Config, 'GITHUB_TOKEN') else ""
                    
                    config = RepositoryConfig(
                        provider="github",
                        token=github_token,
                        owner=owner,
                        repo=repo,
                        branch="main"  # Se puede hacer configurable
                    )
                    
                    logger.info(f"Configuraci√≥n creada: {config.provider}:{config.owner}/{config.repo}")
                    return config
            
            # Agregar soporte para otros proveedores aqu√≠
            elif 'gitlab.com' in repository_url:
                raise Exception("GitLab support not yet implemented")
            elif 'bitbucket.org' in repository_url:
                raise Exception("Bitbucket support not yet implemented")
            
            raise ValueError(f"Formato de URL no soportado: {repository_url}")
            
        except Exception as e:
            logger.error(f"Error creando configuraci√≥n de repositorio: {str(e)}")
            raise Exception(f"Invalid repository URL format: {repository_url}")
    
    async def _load_and_process_rules(self) -> Dict[str, Any]:
        """Carga y procesa todas las reglas de validaci√≥n desde S3 REAL."""
        try:
            logger.debug(f"Iniciando carga de reglas desde S3 REAL: {S3PathHelper.build_full_rules_path()}")
            
            # üèóÔ∏è LAZY: self.rules_manager se carga aqu√≠ si no existe
            processed_rules = await self.rules_manager.load_and_process_rules()
            
            # Verificar que se cargaron reglas
            if not processed_rules['parsed_rules']:
                raise Exception("No se pudieron cargar reglas de validaci√≥n desde S3")
            
            # Validar estructura de reglas
            validation_result = self.rules_manager.validate_rules_structure(processed_rules['parsed_rules'])
            if not validation_result['is_valid']:
                logger.error("Reglas cargadas tienen problemas de estructura")
                for issue in validation_result['issues']:
                    logger.error(f"Problema en reglas: {issue}")
                raise Exception("Las reglas cargadas tienen problemas de estructura")
            
            # Log estad√≠sticas
            stats = processed_rules['processing_metadata'].get('classification_stats', {})
            logger.info(f"Reglas cargadas exitosamente desde S3 REAL:")
            logger.info(f"  - Estructurales: {stats.get('structural', 0)}")
            logger.info(f"  - Contenido: {stats.get('content', 0)}")
            logger.info(f"  - Sem√°nticas: {stats.get('semantic', 0)}")
            logger.info(f"  - Archivos √∫nicos requeridos: {len(processed_rules['required_files'])}")
            logger.info(f"  - Fuente: {processed_rules['processing_metadata'].get('source', 'unknown')}")
            
            return processed_rules
            
        except Exception as e:
            logger.error(f"Error cargando reglas desde S3 REAL: {str(e)}")
            raise Exception(f"Fall√≥ la carga de reglas desde S3: {str(e)}")
    
    async def _load_repository_content_via_real_services(self, repository_config: RepositoryConfig, 
                                                       required_files: List[str]) -> Dict[str, Any]:
        """Carga el contenido del repositorio usando RepositoryAccessManager REAL."""
        try:
            logger.info(f"Cargando contenido v√≠a RepositoryAccessManager REAL: {repository_config.get_repository_url()}")
            logger.debug(f"Archivos requeridos: {len(required_files)}")
            
            # üèóÔ∏è LAZY: self.repository_access_manager se carga aqu√≠ si no existe
            content_result = await self.repository_access_manager.load_repository_content(
                repository_config, required_files
            )
            
            if not content_result.get('success'):
                raise Exception(f"Failed to load repository content: {content_result.get('error')}")
            
            # Extraer datos del resultado
            structure = content_result.get('structure', {})
            files_content = content_result.get('files', {})
            content_stats = content_result.get('content_statistics', {})
            
            logger.info(f"Contenido del repositorio cargado v√≠a servicios AWS REALES:")
            logger.info(f"  - Archivos obtenidos: {content_stats.get('total_files', 0)}")
            logger.info(f"  - Tama√±o total: {content_stats.get('total_size', 0):,} caracteres")
            logger.info(f"  - Tasa de √©xito: {content_stats.get('success_rate', 0):.1f}%")
            
            return {
                'structure': structure,
                'files': files_content,
                'repository_url': repository_config.get_repository_url(),
                'content_statistics': content_stats,
                'access_metadata': content_result.get('access_metadata', {}),
                'service_type': 'RepositoryAccessManager_REAL'
            }
            
        except Exception as e:
            logger.error(f"Error cargando contenido v√≠a servicios REALES: {str(e)}")
            raise Exception(f"Fall√≥ la carga del repositorio v√≠a servicios AWS: {str(e)}")
    
    async def _execute_validations(self, classified_rules: Dict[str, List], 
                                 repository_content: Dict[str, Any]) -> List[ValidationResult]:
        """Ejecuta todas las validaciones en paralelo usando Bedrock REAL."""
        try:
            files_content = repository_content.get('files', {})
            content_stats = repository_content.get('content_statistics', {})
            
            logger.debug("Iniciando ejecuci√≥n de validaciones paralelas con Bedrock REAL")
            logger.debug(f"Contenido disponible: {content_stats.get('total_files', 0)} archivos, "
                        f"{content_stats.get('total_size', 0):,} caracteres")
            
            # üèóÔ∏è LAZY: self.validation_engine se carga aqu√≠ si no existe
            validation_results = await self.validation_engine.execute_parallel_validation(
                classified_rules, files_content
            )
            
            # Verificar que se obtuvieron resultados
            if not validation_results:
                logger.warning("No se generaron resultados de validaci√≥n")
                return []
            
            # Log estad√≠sticas de validaci√≥n
            total_rules = sum(len(rules) for rules in classified_rules.values())
            success_count = len(validation_results)
            
            logger.info(f"Validaciones completadas con Bedrock REAL:")
            logger.info(f"  - Reglas procesadas: {success_count}/{total_rules}")
            logger.info(f"  - Tasa de √©xito: {(success_count/total_rules)*100:.1f}%" if total_rules > 0 else "  - Sin reglas procesadas")
            
            # Log resultados por tipo y criticidad
            self._log_validation_results_summary(validation_results)
            
            return validation_results
            
        except Exception as e:
            logger.error(f"Error ejecutando validaciones con Bedrock REAL: {str(e)}")
            raise Exception(f"Fall√≥ la ejecuci√≥n de validaciones: {str(e)}")
    
    def _log_validation_results_summary(self, validation_results: List[ValidationResult]):
        """Log resumen detallado de los resultados de validaci√≥n."""
        # Resultados por tipo
        results_by_type = {}
        for result in validation_results:
            rule_type = result.rule_type.lower()
            if rule_type not in results_by_type:
                results_by_type[rule_type] = {'cumple': 0, 'no_cumple': 0, 'parcial': 0}
            
            if result.resultado == 'CUMPLE':
                results_by_type[rule_type]['cumple'] += 1
            elif result.resultado == 'NO_CUMPLE':
                results_by_type[rule_type]['no_cumple'] += 1
            else:
                results_by_type[rule_type]['parcial'] += 1
        
        for rule_type, counts in results_by_type.items():
            logger.info(f"  - {rule_type.title()}: {counts['cumple']} ‚úÖ, {counts['no_cumple']} ‚ùå, {counts['parcial']} ‚ö†Ô∏è")
        
        # Resultados por criticidad
        results_by_criticality = {}
        for result in validation_results:
            criticality = result.rule_criticality.lower()
            if criticality not in results_by_criticality:
                results_by_criticality[criticality] = {'cumple': 0, 'no_cumple': 0, 'parcial': 0}
            
            if result.resultado == 'CUMPLE':
                results_by_criticality[criticality]['cumple'] += 1
            elif result.resultado == 'NO_CUMPLE':
                results_by_criticality[criticality]['no_cumple'] += 1
            else:
                results_by_criticality[criticality]['parcial'] += 1
        
        logger.info("  Resultados por criticidad:")
        for criticality, counts in results_by_criticality.items():
            logger.info(f"    - {criticality.title()}: {counts['cumple']} ‚úÖ, {counts['no_cumple']} ‚ùå, {counts['parcial']} ‚ö†Ô∏è")
    
    async def _consolidate_results(self, validation_results: List[ValidationResult], 
                                 processing_context: Dict[str, Any]) -> ConsolidatedResult:
        """Consolida todos los resultados en una decisi√≥n final."""
        try:
            logger.debug("Iniciando consolidaci√≥n de resultados")
            
            # üèóÔ∏è LAZY: self.rules_manager se carga aqu√≠ si no existe  
            consolidated_result = self.rules_manager.process_and_consolidate_results(
                validation_results, processing_context
            )
            
            # Log del resultado final
            logger.info(f"Consolidaci√≥n completada:")
            logger.info(f"  - Decisi√≥n final: {'APROBADO' if consolidated_result.passed else 'RECHAZADO'}")
            logger.info(f"  - Reglas totales: {consolidated_result.total_rules_processed}")
            logger.info(f"  - Fallas cr√≠ticas: {consolidated_result.critical_failures}")
            logger.info(f"  - Fallas medias: {consolidated_result.medium_failures}")
            logger.info(f"  - Fallas bajas: {consolidated_result.low_failures}")
            logger.info(f"  - Errores del sistema: {consolidated_result.system_errors}")
            
            return consolidated_result
            
        except Exception as e:
            logger.error(f"Error consolidando resultados: {str(e)}")
            raise Exception(f"Fall√≥ la consolidaci√≥n de resultados: {str(e)}")
    
    async def _trigger_post_processing(self, consolidated_result: ConsolidatedResult,
                                     repository_url: str, user_info: Dict[str, str]):
        """Dispara el post-procesamiento usando Lambda REAL."""
        try:
            logger.debug("Iniciando post-procesamiento con Lambda REAL")
            
            # Preparar datos para post-procesamiento
            post_processing_data = await self.rules_manager.prepare_for_post_processing(
                consolidated_result, repository_url, user_info
            )
            
            # Agregar metadata de ejecuci√≥n incluyendo stats reales
            post_processing_data['execution_metadata'] = {
                'execution_id': self.execution_stats['execution_id'],
                'execution_time': self.execution_stats['end_time'] - self.execution_stats['start_time'] if self.execution_stats['end_time'] else None,
                'phases_completed': len(self.execution_stats['phases_completed']),
                'system_metrics': MetricsCollector.collect_system_metrics(),
                'repository_access_stats': self.repository_access_manager.get_access_statistics(),
                'lazy_loading_stats': LazyLoadingMonitor.get_loading_statistics(),
                'uses_real_services': True,
                'state_pattern_applied': True  # NUEVO
            }
            
            # Trigger report lambda REAL (fire-and-forget)
            try:
                await self.repository_access_manager.trigger_report(post_processing_data)
                logger.info("Post-procesamiento con Lambda REAL disparado exitosamente")
            except Exception as e:
                logger.warning(f"Post-procesamiento fall√≥ (no cr√≠tico): {str(e)}")
                # No fallar la validaci√≥n por errores de post-procesamiento
            
        except Exception as e:
            logger.warning(f"Error en post-procesamiento: {str(e)}")
            # Post-procesamiento es opcional, no debe fallar la validaci√≥n principal
    
    def _get_processing_context(self) -> Dict[str, Any]:
        """Obtiene el contexto del procesamiento para consolidaci√≥n."""
        current_time = time.time()
        execution_time_ms = None
        
        if self.execution_stats['start_time']:
            execution_time_ms = (current_time - self.execution_stats['start_time']) * 1000
        
        context = {
            'execution_id': self.execution_stats['execution_id'],
            'execution_time_ms': execution_time_ms,
            'phases_completed': self.execution_stats['phases_completed'],
            'system_errors': len(self.execution_stats['errors_encountered']),
            'repository_config': self.execution_stats['repository_config'],
            'processing_metadata': {},
            'system_metrics': MetricsCollector.collect_system_metrics(),
            'lazy_loading_stats': LazyLoadingMonitor.get_loading_statistics(),
            'uses_real_services': True,
            'state_pattern_applied': True  # NUEVO
        }
        
        # Solo agregar stats de componentes que ya est√°n cargados (lazy)
        if self._validation_engine is not None:
            context['processing_metadata']['validation_engine_stats'] = self.validation_engine.get_validation_statistics()
            
        if self._repository_access_manager is not None:
            context['processing_metadata']['repository_access_stats'] = self.repository_access_manager.get_access_statistics()
        
        return context
    
    def _record_phase_completion(self, phase_name: str):
        """Registra la finalizaci√≥n de una fase."""
        completion_time = time.time()
        duration_from_start = completion_time - self.execution_stats['start_time']
        
        self.execution_stats['phases_completed'].append({
            'phase': phase_name,
            'timestamp': completion_time,
            'duration_from_start': duration_from_start,
            'duration_formatted': f"{duration_from_start:.3f}s"
        })
        
        logger.debug(f"Fase completada: {phase_name} (en {duration_from_start:.3f}s)")
    
    def _create_final_response(self, consolidated_result: ConsolidatedResult) -> Dict[str, Any]:
        """Crea la respuesta final simplificada para la Lambda."""
        repository_config = self.execution_stats.get('repository_config')
        
        response = {
            'passed': consolidated_result.passed,
            'message': consolidated_result.message,
            'summary': {
                'total_rules': consolidated_result.total_rules_processed,
                'critical_failures': consolidated_result.critical_failures,
                'medium_failures': consolidated_result.medium_failures,
                'low_failures': consolidated_result.low_failures,
                'execution_time_ms': consolidated_result.execution_time_ms
            },
            'metadata': {
                'execution_id': self.execution_stats['execution_id'],
                'phases_completed': len(self.execution_stats['phases_completed']),
                'total_files_analyzed': self.execution_stats['total_files_analyzed'],
                'errors_encountered': len(self.execution_stats['errors_encountered']),
                'source': 'S3_rulesmetadata.json',
                'repository_provider': repository_config.provider if repository_config else 'unknown',
                'lazy_loading_optimized': True,
                'uses_real_services': True,
                'state_pattern_applied': True,  # NUEVO
                'components_loaded': len([c for c in [
                    self._repository_access_manager, self._rules_manager, self._validation_engine
                ] if c is not None])
            }
        }
        
        # Solo agregar stats si los componentes fueron cargados
        if self._repository_access_manager is not None:
            response['metadata']['repository_access_stats'] = self.repository_access_manager.get_access_statistics()
        
        return response
    
    def _create_error_response(self, error_message: str) -> Dict[str, Any]:
        """Crea una respuesta de error estructurada."""
        execution_time_ms = None
        if self.execution_stats['start_time'] and self.execution_stats['end_time']:
            execution_time_ms = (self.execution_stats['end_time'] - self.execution_stats['start_time']) * 1000
        
        repository_config = self.execution_stats.get('repository_config')
        
        response = {
            'passed': False,
            'message': f"Error del sistema durante la validaci√≥n: {error_message}",
            'summary': {
                'total_rules': 0,
                'critical_failures': 0,
                'medium_failures': 0,
                'low_failures': 0,
                'execution_time_ms': execution_time_ms
            },
            'metadata': {
                'execution_id': self.execution_stats['execution_id'],
                'phases_completed': len(self.execution_stats['phases_completed']),
                'total_files_analyzed': 0,
                'errors_encountered': len(self.execution_stats['errors_encountered']),
                'error_details': self.execution_stats['errors_encountered'],
                'failed_phase': self.execution_stats['phases_completed'][-1]['phase'] if self.execution_stats['phases_completed'] else 'initialization',
                'repository_provider': repository_config.provider if repository_config else 'unknown',
                'lazy_loading_optimized': True,
                'uses_real_services': True,
                'state_pattern_applied': True,  # NUEVO
                'components_loaded_before_error': len([c for c in [
                    self._repository_access_manager, self._rules_manager, self._validation_engine
                ] if c is not None])
            }
        }
        
        # Solo agregar stats si los componentes fueron cargados antes del error
        if self._repository_access_manager is not None:
            response['metadata']['repository_access_stats'] = self.repository_access_manager.get_access_statistics()
        
        return response
    
    # =============================================================================
    # M√âTODOS DE UTILIDAD Y CONFIGURACI√ìN (sin cambios)
    # =============================================================================
    
    def _validate_system_configuration(self):
        """Valida la configuraci√≥n del sistema al inicializar."""
        try:
            # Validar variables de entorno (ligero)
            missing_vars = ConfigValidator.validate_required_env_vars()
            if missing_vars:
                logger.warning(f"Variables de entorno faltantes: {missing_vars}")
            
            logger.debug("Configuraci√≥n del sistema validada (lazy mode)")
            
        except Exception as e:
            logger.warning(f"Error validando configuraci√≥n del sistema: {str(e)}")
    
    def get_execution_statistics(self) -> Dict[str, Any]:
        """Obtiene estad√≠sticas completas de la ejecuci√≥n."""
        execution_time = None
        if self.execution_stats['start_time'] and self.execution_stats['end_time']:
            execution_time = self.execution_stats['end_time'] - self.execution_stats['start_time']
        
        stats = {
            'execution_stats': {
                **self.execution_stats,
                'total_execution_time': execution_time,
                'execution_time_formatted': f"{execution_time:.3f}s" if execution_time else None
            },
            'component_stats': {},
            'system_info': MetricsCollector.collect_system_metrics(),
            'lazy_loading_info': {
                'components_loaded': len([c for c in [
                    self._repository_access_manager, self._rules_manager, self._validation_engine
                ] if c is not None]),
                'total_components': 3,
                'loading_efficiency': 'optimal',
                'factory_stats': ComponentFactory.get_statistics(),
                'all_components_real': True
            },
            'refactoring_applied': {
                'state_pattern': 'Applied to validation phases',
                'complexity_reduction': '15+ ‚Üí 4 decision paths',
                'phase_isolation': 'Each phase is independent and testeable',
                'error_handling': 'Granular per-phase error handling'
            }
        }
        
        # Solo agregar stats de componentes que est√°n cargados
        if self._rules_manager is not None:
            stats['component_stats']['rules_manager'] = self.rules_manager.get_processing_statistics()
        
        if self._validation_engine is not None:
            stats['component_stats']['validation_engine'] = self.validation_engine.get_validation_statistics()
        
        if self._repository_access_manager is not None:
            stats['component_stats']['repository_access_manager'] = self.repository_access_manager.get_access_statistics()
        
        return stats
    
    async def health_check(self) -> Dict[str, Any]:
        """Realiza un health check del sistema completo con servicios REALES."""
        health_status = {
            'overall_status': 'healthy',
            'timestamp': time.time(),
            'components': {},
            'issues': [],
            'lazy_loading_enabled': True,
            'uses_real_services': True,
            'state_pattern_applied': True  # NUEVO
        }
        
        try:
            # Check configuraci√≥n (ligero)
            missing_vars = ConfigValidator.validate_required_env_vars()
            if missing_vars:
                health_status['components']['configuration'] = 'warning'
                health_status['issues'].append(f"Missing env vars: {missing_vars}")
            else:
                health_status['components']['configuration'] = 'healthy'
            
            # Check RepositoryAccessManager health (üèóÔ∏è LAZY: solo si ya est√° cargado)
            if self._repository_access_manager is not None:
                repository_health = self.repository_access_manager.health_check()
                health_status['components']['repository_access_manager'] = repository_health['overall_status']
                if repository_health['issues']:
                    health_status['issues'].extend(repository_health['issues'])
            else:
                health_status['components']['repository_access_manager'] = 'not_loaded'
            
            # Check rules availability (ligero)
            try:
                # Check b√°sico sin cargar rules_manager completo
                import boto3
                s3_test = boto3.client('s3', region_name=Config.AWS_REGION)
                s3_test.head_object(Bucket=Config.S3_BUCKET, Key=Config.RULES_S3_PATH)
                health_status['components']['rules'] = 'healthy'
            except Exception as e:
                health_status['components']['rules'] = 'error'
                health_status['issues'].append(f"Cannot access rules: {str(e)}")
            
            # Determinar estado general
            if any(status == 'error' for status in health_status['components'].values()):
                health_status['overall_status'] = 'error'
            elif any(status == 'warning' for status in health_status['components'].values()):
                health_status['overall_status'] = 'warning'
            
            # Agregar info de lazy loading
            health_status['lazy_loading_stats'] = LazyLoadingMonitor.get_loading_statistics()
            
        except Exception as e:
            health_status['overall_status'] = 'error'
            health_status['issues'].append(f"Health check failed: {str(e)}")
        
        return health_status